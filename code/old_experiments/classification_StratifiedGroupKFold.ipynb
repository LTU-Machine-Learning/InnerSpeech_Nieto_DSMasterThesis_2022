{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init libraries\n",
    "import warnings\n",
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "np.random.seed(23)\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "warnings.filterwarnings(action = \"ignore\", category = DeprecationWarning )\n",
    "warnings.filterwarnings(action = \"ignore\", category = FutureWarning )\n",
    "warnings.filterwarnings(action = \"ignore\", category = ConvergenceWarning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Project defaults\n",
    "# The root dir\n",
    "root_dir = \"./ds003626\"\n",
    "\n",
    "# Sampling rate\n",
    "fs = 256\n",
    "\n",
    "# Select the useful par of each trial. Time in seconds\n",
    "t_start = 1.5\n",
    "t_end = 3.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 10, 10)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "from aux.pre_process import get_subjects_data_and_label, get_subjects_data_label_group\n",
    "\n",
    "condition = \"Inner\"\n",
    "data, labels, groups = get_subjects_data_label_group(root_dir, condition, t_start = t_start, t_end = t_end, fs = fs)\n",
    "len(data), len(labels), len(groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_array=np.vstack(data)\n",
    "label_array=np.hstack(labels)\n",
    "group_array=np.hstack(groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((2236, 128, 512), (2236,), (2236,))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array.shape, label_array.shape, group_array.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "# Define all the features\n",
    "from scipy import stats\n",
    "import antropy as ant\n",
    "\n",
    "def mean(x):\n",
    "    return np.mean(x, axis=-1)\n",
    "\n",
    "def std(x):\n",
    "    return np.std(x, axis=-1)\n",
    "\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.var(x, axis=-1)\n",
    "\n",
    "def minim(x):\n",
    "    return np.min(x, axis=-1)\n",
    "\n",
    "def maxim(x):\n",
    "    return np.max(x, axis=-1)\n",
    "\n",
    "def argminim(x):\n",
    "    return np. argmin(x, axis=-1)\n",
    "\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x,axis=-1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=-1))\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis=-1)\n",
    "\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis=-1)\n",
    "\n",
    "def f_minplusmax(x):\n",
    "    return np.max(x, axis=-1) + np.min(x, axis=-1)\n",
    "\n",
    "def f_maxminusmin(x):\n",
    "    return np.max(x, axis=-1) - np.min(x, axis=-1)\n",
    "\n",
    "def f_spec_entropy(x):\n",
    "    return ant.spectral_entropy(x, fs, method=\"welch\", normalize=True, axis=-1)\n",
    "\n",
    "def f_integral(x):\n",
    "    return integrate.simps(x, axis=-1)\n",
    "\n",
    "def f_petrosian(x):\n",
    "    return ant.petrosian_fd(x, axis=-1)\n",
    "\n",
    "def f_katz(x):\n",
    "    return ant.katz_fd(x, axis=-1)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    # Uncomment the desired line to add the feature\n",
    "    return np.concatenate((\n",
    "        mean(x),\n",
    "        std(x),\n",
    "        ptp(x),\n",
    "        var(x),\n",
    "        minim(x),\n",
    "        maxim(x),\n",
    "        argminim(x),\n",
    "        argmaxim(x),\n",
    "        rms(x),\n",
    "        abs_diff_signal(x),\n",
    "        skewness(x),\n",
    "        kurtosis(x),\n",
    "        # f_minplusmax(x),\n",
    "        # f_maxminusmin(x),\n",
    "        # f_spec_entropy(x),\n",
    "        # f_integral(x),\n",
    "        # f_katz(x),\n",
    "        # f_petrosian(x),\n",
    "    ), axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "features=[]\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))\n",
    "features_array=np.array(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_state = 42\n",
    "splits = [0.10, 0.20, 0.30]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def run_cross_validation(classifier, x_tr, y_tr):\n",
    "    k_fold = model_selection.StratifiedKFold(n_splits=5)\n",
    "    results = model_selection.cross_val_score(classifier, x_tr, y_tr, cv=k_fold, scoring='accuracy')\n",
    "    return results.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape:  (2236, 681)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = features_array\n",
    "y = label_array\n",
    "#X = MinMaxScaler().fit_transform(X)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Select one fs here\n",
    "fs = LinearSVC(C=0.01, penalty=\"l2\", dual=False).fit(X, y)\n",
    "\n",
    "model = SelectFromModel(fs, prefit=True)\n",
    "X = model.transform(X)\n",
    "\n",
    "print(\"New shape: \", X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "inner_cv = StratifiedGroupKFold(n_splits=5)\n",
    "outer_cv = StratifiedGroupKFold(n_splits=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split: Train:90.0% Test:10.0%\n",
      "Classifier: Linear SVC \n",
      "The best parameters found are: {'C': 0.0005, 'dual': True}\n",
      "The mean CV score of the best model is: 0.296\n",
      "Grid scores on development set:\n",
      "\n",
      "0.271 (+/-0.024) for {'C': 1e-05, 'dual': True}\n",
      "0.271 (+/-0.024) for {'C': 1e-05, 'dual': False}\n",
      "0.278 (+/-0.043) for {'C': 0.0001, 'dual': True}\n",
      "0.278 (+/-0.043) for {'C': 0.0001, 'dual': False}\n",
      "0.296 (+/-0.051) for {'C': 0.0005, 'dual': True}\n",
      "0.296 (+/-0.051) for {'C': 0.0005, 'dual': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28        56\n",
      "           1       0.31      0.32      0.31        56\n",
      "           2       0.35      0.38      0.36        56\n",
      "           3       0.31      0.30      0.31        56\n",
      "\n",
      "    accuracy                           0.32       224\n",
      "   macro avg       0.32      0.32      0.32       224\n",
      "weighted avg       0.32      0.32      0.32       224\n",
      "\n",
      "\n",
      "Classifier: SVC \n",
      "The best parameters found are: {'C': 10, 'kernel': 'linear'}\n",
      "The mean CV score of the best model is: 0.299\n",
      "Grid scores on development set:\n",
      "\n",
      "0.262 (+/-0.023) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.244 (+/-0.013) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.279 (+/-0.024) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.278 (+/-0.054) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.272 (+/-0.022) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.293 (+/-0.058) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.272 (+/-0.022) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.299 (+/-0.049) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.299 (+/-0.049) for {'C': 1, 'kernel': 'linear'}\n",
      "0.299 (+/-0.049) for {'C': 10, 'kernel': 'linear'}\n",
      "0.299 (+/-0.049) for {'C': 100, 'kernel': 'linear'}\n",
      "0.299 (+/-0.049) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.46      0.36        56\n",
      "           1       0.35      0.30      0.32        56\n",
      "           2       0.38      0.30      0.34        56\n",
      "           3       0.31      0.23      0.27        56\n",
      "\n",
      "    accuracy                           0.33       224\n",
      "   macro avg       0.33      0.33      0.32       224\n",
      "weighted avg       0.33      0.33      0.32       224\n",
      "\n",
      "\n",
      "\n",
      "Split: Train:80.0% Test:20.0%\n",
      "Classifier: Linear SVC \n",
      "The best parameters found are: {'C': 0.0005, 'dual': True}\n",
      "The mean CV score of the best model is: 0.291\n",
      "Grid scores on development set:\n",
      "\n",
      "0.252 (+/-0.032) for {'C': 1e-05, 'dual': True}\n",
      "0.252 (+/-0.032) for {'C': 1e-05, 'dual': False}\n",
      "0.276 (+/-0.058) for {'C': 0.0001, 'dual': True}\n",
      "0.276 (+/-0.058) for {'C': 0.0001, 'dual': False}\n",
      "0.291 (+/-0.053) for {'C': 0.0005, 'dual': True}\n",
      "0.291 (+/-0.053) for {'C': 0.0005, 'dual': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.25      0.26       112\n",
      "           1       0.25      0.27      0.26       112\n",
      "           2       0.23      0.26      0.25       112\n",
      "           3       0.34      0.31      0.33       112\n",
      "\n",
      "    accuracy                           0.27       448\n",
      "   macro avg       0.28      0.27      0.27       448\n",
      "weighted avg       0.28      0.27      0.27       448\n",
      "\n",
      "\n",
      "Classifier: SVC \n",
      "The best parameters found are: {'C': 1, 'kernel': 'linear'}\n",
      "The mean CV score of the best model is: 0.308\n",
      "Grid scores on development set:\n",
      "\n",
      "0.255 (+/-0.049) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.246 (+/-0.020) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.293 (+/-0.041) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.281 (+/-0.045) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.287 (+/-0.033) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.307 (+/-0.024) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.287 (+/-0.033) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.299 (+/-0.038) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.308 (+/-0.027) for {'C': 1, 'kernel': 'linear'}\n",
      "0.308 (+/-0.027) for {'C': 10, 'kernel': 'linear'}\n",
      "0.308 (+/-0.027) for {'C': 100, 'kernel': 'linear'}\n",
      "0.308 (+/-0.027) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.45      0.36       112\n",
      "           1       0.29      0.26      0.27       112\n",
      "           2       0.29      0.24      0.26       112\n",
      "           3       0.34      0.27      0.30       112\n",
      "\n",
      "    accuracy                           0.30       448\n",
      "   macro avg       0.30      0.30      0.30       448\n",
      "weighted avg       0.30      0.30      0.30       448\n",
      "\n",
      "\n",
      "\n",
      "Split: Train:70.0% Test:30.0%\n",
      "Classifier: Linear SVC \n",
      "The best parameters found are: {'C': 0.0005, 'dual': True}\n",
      "The mean CV score of the best model is: 0.293\n",
      "Grid scores on development set:\n",
      "\n",
      "0.255 (+/-0.036) for {'C': 1e-05, 'dual': True}\n",
      "0.255 (+/-0.036) for {'C': 1e-05, 'dual': False}\n",
      "0.267 (+/-0.039) for {'C': 0.0001, 'dual': True}\n",
      "0.267 (+/-0.039) for {'C': 0.0001, 'dual': False}\n",
      "0.293 (+/-0.033) for {'C': 0.0005, 'dual': True}\n",
      "0.293 (+/-0.033) for {'C': 0.0005, 'dual': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.27      0.27       168\n",
      "           1       0.30      0.29      0.30       167\n",
      "           2       0.31      0.30      0.31       168\n",
      "           3       0.27      0.29      0.28       168\n",
      "\n",
      "    accuracy                           0.29       671\n",
      "   macro avg       0.29      0.29      0.29       671\n",
      "weighted avg       0.29      0.29      0.29       671\n",
      "\n",
      "\n",
      "Classifier: SVC \n",
      "The best parameters found are: {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "The mean CV score of the best model is: 0.297\n",
      "Grid scores on development set:\n",
      "\n",
      "0.268 (+/-0.028) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.237 (+/-0.023) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.277 (+/-0.070) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.279 (+/-0.044) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.273 (+/-0.072) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.297 (+/-0.043) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.273 (+/-0.072) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.281 (+/-0.046) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.292 (+/-0.068) for {'C': 1, 'kernel': 'linear'}\n",
      "0.292 (+/-0.068) for {'C': 10, 'kernel': 'linear'}\n",
      "0.292 (+/-0.068) for {'C': 100, 'kernel': 'linear'}\n",
      "0.292 (+/-0.068) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.31      0.29       168\n",
      "           1       0.33      0.34      0.33       167\n",
      "           2       0.35      0.28      0.31       168\n",
      "           3       0.28      0.30      0.29       168\n",
      "\n",
      "    accuracy                           0.31       671\n",
      "   macro avg       0.31      0.31      0.31       671\n",
      "weighted avg       0.31      0.31      0.31       671\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Run Nested cross-validation\n",
    "\n",
    "classifiers = [\n",
    "    [\"Linear SVC\", LinearSVC(), {'C': [0.00001, 0.0001, 0.0005], 'dual': (True, False)}],\n",
    "    [\"SVC\", SVC(), [{\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]}, {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]}, ]],\n",
    "]\n",
    "\n",
    "for test_size in splits:\n",
    "    print(\"\\nSplit: Train:{}% Test:{}%\".format(100 - (test_size * 100), test_size * 100))\n",
    "\n",
    "    # Stratify guarantees that the same proportion of the classes will be available in train and test\n",
    "    x_train, x_test, y_train, y_test, g_train, g_test = train_test_split(X, y, group_array, test_size=test_size, stratify=y)\n",
    "\n",
    "    for cls in classifiers:\n",
    "        print('{}: {} '.format(\"Classifier\", cls[0]))\n",
    "        clf = GridSearchCV(estimator=cls[1], param_grid=cls[2], cv=inner_cv, n_jobs=-1)\n",
    "        clf.fit(x_train, y_train, groups=g_train)\n",
    "        print(f\"The best parameters found are: {clf.best_params_}\")\n",
    "        print(f\"The mean CV score of the best model is: {clf.best_score_:.3f}\")\n",
    "\n",
    "        print(\"Grid scores on development set:\\n\")\n",
    "        means = clf.cv_results_[\"mean_test_score\"]\n",
    "        stds = clf.cv_results_[\"std_test_score\"]\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "        print(\"\\nDetailed classification report:\\n\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\\n\")\n",
    "        y_true, y_pred = y_test, clf.predict(x_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier                               Accuracy             Cross validation\n",
      "Linear SVC                               0.28295454545454546  0.29573746472758844\n",
      "SVC                                      0.2943181818181818   0.28095289776427174\n",
      "Classifier                               Accuracy             Cross validation\n",
      "Linear SVC                               0.3045977011494253   0.29285714285714287\n",
      "SVC                                      0.27155172413793105  0.2857142857142857\n",
      "Classifier                               Accuracy             Cross validation\n",
      "Linear SVC                               0.3106060606060606   0.2988587502511553\n",
      "SVC                                      0.3151515151515151   0.3007615029134017\n"
     ]
    }
   ],
   "source": [
    "# Run the regular tests\n",
    "classifiers = [\n",
    "    [\"Linear SVC\", LinearSVC(random_state=random_state, max_iter=10000, C=0.0005)],\n",
    "    [\"SVC\", SVC(random_state=random_state, max_iter=10000, C=10, kernel='linear')],\n",
    "]\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in cv.split(X, y, group_array):\n",
    "    print('{:<40} {:<20} {:<15}'.format(\"Classifier\", \"Accuracy\", \"Cross validation\"))\n",
    "\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for cls in classifiers:\n",
    "        cls[1].fit(x_train, y_train)\n",
    "        y_pred = cls[1].predict(x_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        cross_v = run_cross_validation(cls[1], x_train, y_train)\n",
    "        print('{:<40} {:<20} {:<15}'.format(cls[0], accuracy, cross_v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}