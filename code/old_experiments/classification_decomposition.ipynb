{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(23)\n",
    "\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "warnings.filterwarnings(action = \"ignore\", category = DeprecationWarning )\n",
    "warnings.filterwarnings(action = \"ignore\", category = FutureWarning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The root dir\n",
    "root_dir = \"./ds003626\"\n",
    "\n",
    "# Sampling rate\n",
    "fs = 256\n",
    "\n",
    "# Select the useful par of each trial. Time in seconds\n",
    "t_start = 1.5\n",
    "t_end = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using CUDA device 0\n",
      "Enabling CUDA with 9.24 GB available memory\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "mne.utils.set_config('MNE_USE_CUDA', 'true')\n",
    "mne.cuda.init_cuda(verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [03:31<00:00,  1.06s/it]\n",
      "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
      "100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
      "100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:32<00:00,  1.06s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:35<00:00,  1.08s/it]\n",
      "100%|██████████| 140/140 [02:30<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:31<00:00,  1.06s/it]\n",
      "100%|██████████| 100/100 [01:45<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:31<00:00,  1.06s/it]\n",
      "100%|██████████| 200/200 [03:31<00:00,  1.06s/it]\n",
      "100%|██████████| 200/200 [03:28<00:00,  1.04s/it]\n",
      "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:32<00:00,  1.06s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 100/100 [01:47<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:35<00:00,  1.08s/it]\n",
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:32<00:00,  1.06s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:33<00:00,  1.07s/it]\n",
      "100%|██████████| 140/140 [02:29<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 200/200 [03:34<00:00,  1.07s/it]\n",
      "100%|██████████| 100/100 [01:47<00:00,  1.08s/it]\n",
      "100%|██████████| 200/200 [03:35<00:00,  1.08s/it]\n",
      "100%|██████████| 200/200 [03:35<00:00,  1.08s/it]\n",
      "100%|██████████| 200/200 [03:35<00:00,  1.08s/it]\n",
      "100%|██████████| 200/200 [03:30<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:29<00:00,  1.05s/it]\n",
      "100%|██████████| 200/200 [03:28<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "from aux.pre_process import get_subjects_data_and_label, get_subjects_data_and_label2\n",
    "\n",
    "condition = \"Inner\"\n",
    "\n",
    "data, labels = get_subjects_data_and_label2(root_dir, condition, t_start = t_start, t_end = t_end, fs = fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects 10\n",
      "Data shape: [trials x channels x samples]\n",
      "Shape (200, 27648)\n",
      "Labels\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of subjects\", len(data))\n",
    "print(\"Data shape: [trials x channels x samples]\")\n",
    "print(\"Shape\", data[0].shape) # Trials, channels, samples\n",
    "\n",
    "print(\"Labels\")\n",
    "print(len(labels)) # Time stamp, class , condition, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2236, 27648) (2236,)\n"
     ]
    }
   ],
   "source": [
    "data_array=np.vstack(data)\n",
    "label_array=np.hstack(labels)\n",
    "features_array=data_array\n",
    "print(data_array.shape, label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, roc_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# This section contains the function to support the model evaluation\n",
    "\n",
    "\n",
    "def run_cross_validation(classifier, x_tr, y_tr):\n",
    "    k_fold = model_selection.KFold(n_splits=10)\n",
    "    results = model_selection.cross_val_score(classifier, x_tr, y_tr, cv=k_fold, scoring='accuracy')\n",
    "    print('{:<50} {:.4f}'.format(\"Cross validation average accuracy with 10-fold:\", (results.mean())))\n",
    "\n",
    "def run_accuracy(y_tst, y_p):\n",
    "    print('{:<50} {:.4f}'.format(\"Accuracy\", (metrics.accuracy_score(y_tst, y_p))))\n",
    "\n",
    "def plot_confusion_matrix(y_tst, y_pred, y_labels):\n",
    "    lbs = y_labels.unique()\n",
    "    confusion_matrix = metrics.confusion_matrix(y_tst, y_pred)\n",
    "    matrix_df = pd.DataFrame(confusion_matrix)\n",
    "    ax = plt.axes()\n",
    "    sns.set(font_scale=1.3)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "    ax.set_yticklabels(list(lbs), rotation = 0)\n",
    "    plt.show()\n",
    "\n",
    "# Extract importance\n",
    "def print_importance(classifier, x_tr):\n",
    "    importance = pd.DataFrame({'feature': x_tr.columns, 'importance' : np.round(classifier.feature_importances_, 3)})\n",
    "    importance.sort_values('importance', ascending=False, inplace = True)\n",
    "    print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy                                           0.2355\n",
      "Cross validation average accuracy with 10-fold:    0.2249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.20      0.24       183\n",
      "           1       0.25      0.25      0.25       169\n",
      "           2       0.22      0.29      0.25       156\n",
      "           3       0.20      0.21      0.20       163\n",
      "\n",
      "    accuracy                           0.24       671\n",
      "   macro avg       0.24      0.24      0.24       671\n",
      "weighted avg       0.24      0.24      0.24       671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_random_forest():\n",
    "    print(\"Random Forest\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.30) # 70% test and 30% training\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "run_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network\n",
      "Accuracy                                           0.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation average accuracy with 10-fold:    0.2344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.03      0.05       137\n",
      "           1       0.00      0.00      0.00       103\n",
      "           2       0.00      0.00      0.00       106\n",
      "           3       0.22      0.91      0.35       102\n",
      "\n",
      "    accuracy                           0.22       448\n",
      "   macro avg       0.10      0.24      0.10       448\n",
      "weighted avg       0.11      0.22      0.10       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_neural_network():\n",
    "    print(\"Neural Network\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.20) # 80% test and 20% training\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #plot_confusion_matrix(y_test, y_pred, label_array)\n",
    "\n",
    "run_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy                                           0.2254\n",
      "Cross validation average accuracy with 10-fold:    0.2137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.21      0.23       112\n",
      "           1       0.36      0.15      0.21       134\n",
      "           2       0.18      0.24      0.20       102\n",
      "           3       0.20      0.34      0.25       100\n",
      "\n",
      "    accuracy                           0.23       448\n",
      "   macro avg       0.25      0.23      0.22       448\n",
      "weighted avg       0.26      0.23      0.22       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiclass Random Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def run_random_forest_multi_class():\n",
    "    print(\"Random Forest\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.20) # 80% test and 20% training\n",
    "    rf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=8, criterion='gini')\n",
    "    clf = OneVsRestClassifier(rf)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #print_importance(clf, x_train)\n",
    "    #plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "run_random_forest_multi_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy                                           0.2634\n",
      "Cross validation average accuracy with 10-fold:    0.2209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.21      0.24       114\n",
      "           1       0.23      0.30      0.26       103\n",
      "           2       0.30      0.21      0.25       121\n",
      "           3       0.26      0.34      0.30       110\n",
      "\n",
      "    accuracy                           0.26       448\n",
      "   macro avg       0.27      0.27      0.26       448\n",
      "weighted avg       0.27      0.26      0.26       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def run_random_forest(X, y):\n",
    "    print(\"Random Forest\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20) # 80% test and 20% training\n",
    "    clf = RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=8, criterion='gini')\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    #print_importance(clf, x_train)\n",
    "    #plot_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "run_random_forest(features_array, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy                                           0.2746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_linear_svc_multi_class():\n",
    "    print(\"Linear SVC\")\n",
    "    # Split dataset into training set and test set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.20) # 80% test and 20% training\n",
    "    rf = LinearSVC(random_state=0, max_iter=10000)\n",
    "    clf = OneVsRestClassifier(rf)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    run_accuracy(y_test, y_pred)\n",
    "    run_cross_validation(clf, x_train, y_train)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "run_linear_svc_multi_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import rcParams\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def plot_result(history):\n",
    "    rcParams['figure.figsize'] = (18, 8)\n",
    "    rcParams['axes.spines.top'] = False\n",
    "    rcParams['axes.spines.right'] = False\n",
    "\n",
    "    plt.plot(\n",
    "    np.arange(1, 101),\n",
    "        history.history['loss'], label='Loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(1, 101),\n",
    "        history.history['accuracy'], label='Accuracy'\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(1, 101),\n",
    "        history.history['precision'], label='Precision'\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(1, 101),\n",
    "        history.history['recall'], label='Recall'\n",
    "    )\n",
    "    plt.title('Evaluation metrics', size=20)\n",
    "    plt.xlabel('Epoch', size=14)\n",
    "    plt.legend()\n",
    "\n",
    "def run_prediction(model, x_test):\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "def run_tensor_flow():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features_array, label_array, test_size=0.20) # 80% test and 20% training\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.binary_crossentropy,\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=0.03),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    history = model.fit(x_train, y_train, epochs=100)\n",
    "\n",
    "    plot_result(history)\n",
    "    run_prediction(model, x_test)\n",
    "\n",
    "run_tensor_flow()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}