{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init libraries\n",
    "import warnings\n",
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "np.random.seed(23)\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "warnings.filterwarnings(action = \"ignore\", category = DeprecationWarning )\n",
    "warnings.filterwarnings(action = \"ignore\", category = FutureWarning )\n",
    "warnings.filterwarnings(action = \"ignore\", category = ConvergenceWarning )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Project defaults\n",
    "# The root dir\n",
    "root_dir = \"./ds003626\"\n",
    "\n",
    "# Sampling rate\n",
    "fs = 256\n",
    "\n",
    "# Select the useful par of each trial. Time in seconds\n",
    "t_start = 1.5\n",
    "t_end = 3.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 10, 10)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "from aux.pre_process import get_subjects_data_and_label, get_subjects_data_label_group\n",
    "\n",
    "condition = \"Inner\"\n",
    "data, labels, groups = get_subjects_data_label_group(root_dir, condition, t_start = t_start, t_end = t_end, fs = fs)\n",
    "len(data), len(labels), len(groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_array=np.vstack(data)\n",
    "label_array=np.hstack(labels)\n",
    "group_array=np.hstack(groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.56632558e-06  9.29798573e-06  2.67945790e-06 ...  1.61658549e-05\n",
      "   1.04383488e-05  1.65976586e-05]\n",
      " [ 6.73392992e-06  9.67485813e-06  3.46813168e-06 ...  1.72691653e-05\n",
      "   1.09798877e-05  1.68224439e-05]\n",
      " [ 6.44456485e-06  1.05683281e-05  4.08183062e-06 ...  1.62432293e-05\n",
      "   1.10782575e-05  1.67439421e-05]\n",
      " ...\n",
      " [ 7.73143200e-06  1.17620983e-05  5.96924569e-06 ...  9.61573311e-07\n",
      "  -5.92098200e-06 -5.22468805e-06]\n",
      " [ 1.22760126e-05  1.52803701e-05  1.24073505e-05 ... -2.36157544e-06\n",
      "  -1.04331358e-05 -6.78143929e-06]\n",
      " [ 1.31543686e-05  1.57064520e-05  1.26855428e-05 ... -1.16832456e-06\n",
      "  -9.74268987e-06 -7.23316007e-06]]\n"
     ]
    }
   ],
   "source": [
    "data_array.shape, label_array.shape, group_array.shape\n",
    "print(data_array[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "# Define all the features\n",
    "from scipy import stats\n",
    "import antropy as ant\n",
    "\n",
    "def mean(x):\n",
    "    return np.mean(x, axis=-1)\n",
    "\n",
    "def std(x):\n",
    "    return np.std(x, axis=-1)\n",
    "\n",
    "def ptp(x):\n",
    "    return np.ptp(x, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.var(x, axis=-1)\n",
    "\n",
    "def minim(x):\n",
    "    return np.min(x, axis=-1)\n",
    "\n",
    "def maxim(x):\n",
    "    return np.max(x, axis=-1)\n",
    "\n",
    "def argminim(x):\n",
    "    return np. argmin(x, axis=-1)\n",
    "\n",
    "def argmaxim(x):\n",
    "    return np.argmax(x,axis=-1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2, axis=-1))\n",
    "\n",
    "def abs_diff_signal(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "\n",
    "def skewness(x):\n",
    "    return stats.skew(x, axis=-1)\n",
    "\n",
    "def kurtosis(x):\n",
    "    return stats.kurtosis(x, axis=-1)\n",
    "\n",
    "def f_minplusmax(x):\n",
    "    return np.max(x, axis=-1) + np.min(x, axis=-1)\n",
    "\n",
    "def f_maxminusmin(x):\n",
    "    return np.max(x, axis=-1) - np.min(x, axis=-1)\n",
    "\n",
    "def f_spec_entropy(x):\n",
    "    return ant.spectral_entropy(x, fs, method=\"welch\", normalize=True, axis=-1)\n",
    "\n",
    "def f_integral(x):\n",
    "    return integrate.simps(x, axis=-1)\n",
    "\n",
    "def f_petrosian(x):\n",
    "    return ant.petrosian_fd(x, axis=-1)\n",
    "\n",
    "def f_katz(x):\n",
    "    return ant.katz_fd(x, axis=-1)\n",
    "\n",
    "def concatenate_features(x):\n",
    "    # Uncomment the desired line to add the feature\n",
    "    return np.concatenate((\n",
    "        mean(x),\n",
    "        std(x),\n",
    "        ptp(x),\n",
    "        var(x),\n",
    "        minim(x),\n",
    "        maxim(x),\n",
    "        argminim(x),\n",
    "        argmaxim(x),\n",
    "        rms(x),\n",
    "        abs_diff_signal(x),\n",
    "        skewness(x),\n",
    "        kurtosis(x),\n",
    "    ), axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(2236, 1536)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[]\n",
    "for d in data_array:\n",
    "    features.append(concatenate_features(d))\n",
    "features_array=np.array(features)\n",
    "print(features_array[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "random_state = 42\n",
    "splits = [0.10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def run_cross_validation(classifier, k_fold, x_tr, y_tr, group):\n",
    "    results = model_selection.cross_val_score(classifier, x_tr, y_tr, cv=k_fold, scoring='accuracy', groups=group)\n",
    "    return results.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape:  (2236, 1536)\n",
      "New shape:  (2236, 681)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = features_array\n",
    "y = label_array\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Feature Selection - There are other parameters we could set for Feature Selection\n",
    "print(\"Old shape: \", X.shape)\n",
    "\n",
    "# Select one fs here\n",
    "fs = LinearSVC(C=0.01, penalty=\"l2\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(fs, prefit=True)\n",
    "X = model.transform(X)\n",
    "\n",
    "print(\"New shape: \", X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "inner_cv = StratifiedGroupKFold(n_splits=5)\n",
    "outer_cv = StratifiedGroupKFold(n_splits=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split: Train:90.0% Test:10.0%\n",
      "Classifier: Linear SVC \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/rollin/anaconda3/envs/thesis/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters found are: {'C': 1000, 'dual': True}\n",
      "The mean CV score of the best model is: 0.324\n",
      "Grid scores on development set:\n",
      "\n",
      "0.271 (+/-0.024) for {'C': 1e-05, 'dual': True}\n",
      "0.271 (+/-0.024) for {'C': 1e-05, 'dual': False}\n",
      "0.278 (+/-0.043) for {'C': 0.0001, 'dual': True}\n",
      "0.278 (+/-0.043) for {'C': 0.0001, 'dual': False}\n",
      "0.296 (+/-0.051) for {'C': 0.0005, 'dual': True}\n",
      "0.296 (+/-0.051) for {'C': 0.0005, 'dual': False}\n",
      "0.320 (+/-0.027) for {'C': 1, 'dual': True}\n",
      "0.318 (+/-0.053) for {'C': 1, 'dual': False}\n",
      "0.315 (+/-0.047) for {'C': 10, 'dual': True}\n",
      "0.317 (+/-0.042) for {'C': 10, 'dual': False}\n",
      "0.315 (+/-0.035) for {'C': 100, 'dual': True}\n",
      "0.316 (+/-0.039) for {'C': 100, 'dual': False}\n",
      "0.324 (+/-0.045) for {'C': 1000, 'dual': True}\n",
      "0.317 (+/-0.050) for {'C': 1000, 'dual': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.34      0.31        56\n",
      "           1       0.26      0.21      0.24        56\n",
      "           2       0.36      0.32      0.34        56\n",
      "           3       0.40      0.45      0.42        56\n",
      "\n",
      "    accuracy                           0.33       224\n",
      "   macro avg       0.33      0.33      0.33       224\n",
      "weighted avg       0.33      0.33      0.33       224\n",
      "\n",
      "\n",
      "Classifier: SVC \n",
      "The best parameters found are: {'C': 10, 'kernel': 'linear'}\n",
      "The mean CV score of the best model is: 0.299\n",
      "Grid scores on development set:\n",
      "\n",
      "0.242 (+/-0.005) for {'C': 1e-05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.242 (+/-0.005) for {'C': 1e-05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.242 (+/-0.005) for {'C': 0.0001, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.242 (+/-0.005) for {'C': 0.0001, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.242 (+/-0.005) for {'C': 0.0005, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.242 (+/-0.005) for {'C': 0.0005, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.262 (+/-0.023) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.244 (+/-0.013) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.279 (+/-0.024) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.278 (+/-0.054) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.272 (+/-0.022) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.293 (+/-0.058) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.272 (+/-0.022) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.299 (+/-0.049) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.242 (+/-0.005) for {'C': 1e-05, 'kernel': 'linear'}\n",
      "0.234 (+/-0.019) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.256 (+/-0.027) for {'C': 0.0005, 'kernel': 'linear'}\n",
      "0.299 (+/-0.049) for {'C': 1, 'kernel': 'linear'}\n",
      "0.299 (+/-0.049) for {'C': 10, 'kernel': 'linear'}\n",
      "0.299 (+/-0.049) for {'C': 100, 'kernel': 'linear'}\n",
      "0.299 (+/-0.049) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.46      0.36        56\n",
      "           1       0.35      0.30      0.32        56\n",
      "           2       0.38      0.30      0.34        56\n",
      "           3       0.31      0.23      0.27        56\n",
      "\n",
      "    accuracy                           0.33       224\n",
      "   macro avg       0.33      0.33      0.32       224\n",
      "weighted avg       0.33      0.33      0.32       224\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Run Nested cross-validation\n",
    "\n",
    "classifiers = [\n",
    "    [\"Linear SVC\", LinearSVC(), {'C': [0.00001, 0.0001, 0.0005, 1, 10, 100, 1000], 'dual': (True, False)}],\n",
    "    [\"SVC\", SVC(), [{\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [0.00001, 0.0001, 0.0005, 1, 10, 100, 1000]}, {\"kernel\": [\"linear\"], \"C\": [0.00001, 0.0001, 0.0005, 1, 10, 100, 1000]}, ]], # The third parameter here is an array\n",
    "]\n",
    "\n",
    "for test_size in splits:\n",
    "    print(\"\\nSplit: Train:{}% Test:{}%\".format(100 - (test_size * 100), test_size * 100))\n",
    "\n",
    "    # Stratify guarantees that the same proportion of the classes will be available in train and test\n",
    "    x_train, x_test, y_train, y_test, g_train, g_test = train_test_split(X, y, group_array, test_size=test_size, stratify=y)\n",
    "\n",
    "    for cls in classifiers:\n",
    "        print('{}: {} '.format(\"Classifier\", cls[0]))\n",
    "        clf = GridSearchCV(estimator=cls[1], param_grid=cls[2], cv=inner_cv, n_jobs=-1)\n",
    "        clf.fit(x_train, y_train, groups=g_train)\n",
    "        print(f\"The best parameters found are: {clf.best_params_}\")\n",
    "        print(f\"The mean CV score of the best model is: {clf.best_score_:.3f}\")\n",
    "\n",
    "        print(\"Grid scores on development set:\\n\")\n",
    "        means = clf.cv_results_[\"mean_test_score\"]\n",
    "        stds = clf.cv_results_[\"std_test_score\"]\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "        print(\"\\nDetailed classification report:\\n\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\\n\")\n",
    "        y_true, y_pred = y_test, clf.predict(x_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split: Train:90.0% Test:10.0%\n",
      "Classifier                               Accuracy             Cross validation\n",
      "Linear SVC                               0.34375              0.29961930282731164\n",
      "SVC                                      0.29910714285714285  0.3143670678048091\n"
     ]
    }
   ],
   "source": [
    "# Run the regular tests\n",
    "classifiers = [\n",
    "    [\"Linear SVC\", LinearSVC(random_state=random_state, max_iter=10000, C=10)],\n",
    "    [\"SVC\", SVC(random_state=random_state, max_iter=10000, C=10, kernel='linear')],\n",
    "]\n",
    "\n",
    "for test_size in splits:\n",
    "    print(\"\\nSplit: Train:{}% Test:{}%\".format(100 - (test_size * 100), test_size * 100))\n",
    "    print('{:<40} {:<20} {:<15}'.format(\"Classifier\", \"Accuracy\", \"Cross validation\"))\n",
    "\n",
    "    # Stratify guarantees that the same proportion of the classes will be available in train and test\n",
    "    x_train, x_test, y_train, y_test, g_train, g_test = train_test_split(X, y, group_array, test_size=test_size, stratify=y)\n",
    "\n",
    "    for cls in classifiers:\n",
    "        cls[1].fit(x_train, y_train)\n",
    "        y_pred = cls[1].predict(x_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        cross_v = run_cross_validation(cls[1], outer_cv, x_train, y_train, g_train)\n",
    "        print('{:<40} {:<20} {:<15}'.format(cls[0], accuracy, cross_v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}